{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from functools import cmp_to_key\n",
    "import itertools\n",
    "\n",
    "def isNaN(string):\n",
    "    return string != string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = r'/Users/Dasha/work/UMCG/data/MR/results2/mibiogen/mibiogenOct2020/MR_mibiogen_oct2020.xlsx'\n",
    "sh1 = 'gwas-mb'\n",
    "sh2 = 'mb-gwas'\n",
    "#sh1 = \"UKB-mb\"\n",
    "#sh2 = \"mb-UKB\"\n",
    "df1 = pd.read_excel (fname, sheet_name=sh1)\n",
    "df2 = pd.read_excel (fname, sheet_name=sh2)\n",
    "df1['exposure'] = [x for (x,y) in df1['exposure'].str.split(\" \\|\\| \").to_list()]\n",
    "df2['outcome'] = [x for (x,y) in df2['outcome'].str.split(\" \\|\\| \").to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tmp'] = df1['id.exposure'] + \":\" + df1['outcome']\n",
    "df2['tmp'] = df2['id.outcome'] + \":\" + df2['exposure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1new = pd.merge(df1, df2[['tmp', 'pval']], on ='tmp', how ='left')\n",
    "df1new.rename(columns = {\"pval_x\" : \"pval\", \"pval_y\" : \"reverse_MR_pval\"}, inplace=True)\n",
    "\n",
    "df2new = pd.merge(df2, df1[['tmp', 'pval']], on ='tmp', how ='left')\n",
    "df2new.rename(columns = {\"pval_x\" : \"pval\", \"pval_y\" : \"reverse_MR_pval\"}, inplace=True)\n",
    "\n",
    "df1new.drop('tmp', inplace=True, axis=1)\n",
    "df2new.drop('tmp', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_failed_flts(row):\n",
    "    flt_line = \"-\"\n",
    "    if int(row['nsnp']) < 3:\n",
    "        flt_line += ';Number of SNPs'\n",
    "    if not isNaN(row['egger_intercept_pval']):\n",
    "        if float(row['egger_intercept_pval']) < 0.05:\n",
    "            flt_line += ';Egger intercept p-value'\n",
    "    if not isNaN(row['weighted_median_pval']):        \n",
    "        if float(row['weighted_median_pval']) > 0.05:\n",
    "            flt_line += ';Weighted median p-value'\n",
    "    if not isNaN(row['mr_presso_global']):        \n",
    "        if not isNaN(row['mr_presso_outlier_cor_pval']):\n",
    "            if row['mr_presso_global'] == '<1e-04':\n",
    "                if float(row['mr_presso_outlier_cor_pval']) > 0.05:\n",
    "                    flt_line += ';MR PRESSO outlier test'\n",
    "            elif float(row['mr_presso_global']) < 0.05 and float(row['mr_presso_outlier_cor_pval']) > 0.05:\n",
    "                flt_line += ';MR PRESSO outlier test'\n",
    "    if not isNaN(row['mr_presso_pval']):\n",
    "        if float(row['mr_presso_pval']) > 0.05:\n",
    "            flt_line += ';MR PRESSO p-value'\n",
    "    # Leave-one-out updated to filter out only cases with exactly 1 p-value > 0.05\n",
    "    loo_pvals = row['leave_one_out_pval']\n",
    "    pval_cnt = 0\n",
    "    if not isNaN(loo_pvals):\n",
    "        for pval in map(float, loo_pvals.split(\",\")):\n",
    "            if pval > 0.05:\n",
    "                pval_cnt += 1\n",
    "        if pval_cnt == 1:\n",
    "            flt_line += ';Leave-one-out analysis'\n",
    "        if not isNaN(row['reverse_MR_pval']):\n",
    "            if float(row['reverse_MR_pval']) < 0.05:\n",
    "                flt_line += ';Reverse MR p-value'\n",
    "    return(flt_line.replace(\"-;\", \"\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1new['failed_filters'] = df1new.apply (lambda row: get_failed_flts(row), axis=1)\n",
    "df2new['failed_filters'] = df2new.apply (lambda row: get_failed_flts(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter by samplesize: take the largest of the duplicated traits\n",
    "samplesize_dict = {}\n",
    "with open(\"C:/Users/Dasha/work/UMCG/data/MR/data/MRBase_all_outcomes.271020.txt\") as f:\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        spl = l.split(\"\\t\")\n",
    "        samplesize_dict[spl[1]] = spl[14]\n",
    "\n",
    "df1new['samplesize'] = df1new['id.exposure'].replace(samplesize_dict, inplace = False)\n",
    "df2new['samplesize'] = df2new['id.outcome'].replace(samplesize_dict, inplace = False)\n",
    "\n",
    "\n",
    "df1new = add_samplesize_filter(df1new)\n",
    "df2new = add_samplesize_filter(df2new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparator(x, y):\n",
    "    #ss_col = 3\n",
    "    #nsnp_col = 5\n",
    "    ss_col = 'samplesize'\n",
    "    nsnp_col = 'nsnp'\n",
    "    if int(x[ss_col]) > int(y[ss_col]):\n",
    "        return -1\n",
    "    if int(x[ss_col]) < int(y[ss_col]):\n",
    "        return 1\n",
    "    if int(x[ss_col]) == int(y[ss_col]):\n",
    "        if int(x[nsnp_col]) > int(y[nsnp_col]):\n",
    "            return -1\n",
    "        if int(x[nsnp_col]) < int(y[nsnp_col]):\n",
    "            return 1\n",
    "        if int(x[nsnp_col]) == int(y[nsnp_col]):\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_samplesize_filter(df):\n",
    "    df['filter_samplesize'] = \"FALSE\"\n",
    "    pair2line = defaultdict(list)\n",
    "    for index, row in df.iterrows():\n",
    "        pair2line[row['exposure'] + \":\" + row['outcome']].append(row)\n",
    "    for p, row_lst in pair2line.items():\n",
    "        row_lst.sort(key=cmp_to_key(comparator))\n",
    "        row_lst[0]['filter_samplesize'] = \"TRUE\"\n",
    "    return (pd.DataFrame(list(itertools.chain(*pair2line.values()))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the intermediate tables with failed filters column but without removing anything\n",
    "with pd.ExcelWriter(fname, mode='a') as writer:  \n",
    "    df1new.to_excel(writer, sheet_name=sh1+'_all', na_rep = 'NA')\n",
    "    df2new.to_excel(writer, sheet_name=sh2+'_all', na_rep = 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_to_remove = [\"family.Bifidobacteriaceae.id.433\", \"family.unknownfamily.id.1000001214\", \"genus.unknowngenus.id.1000001215\"]\n",
    "\n",
    "df1new_flt = df1new[(df1new.nsnp > 2) & (df1new.filter_samplesize == \"TRUE\") & (~df1new.outcome.isin(taxa_to_remove)) & (~df1new.exposure.isin(taxa_to_remove))]\n",
    "df2new_flt = df2new[(df2new.nsnp > 2) & (df2new.filter_samplesize == \"TRUE\") & (~df2new.outcome.isin(taxa_to_remove)) & (~df2new.exposure.isin(taxa_to_remove))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.multitest as multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df1new_flt['BH_qval'] = multi.multipletests(df1new_flt['pval'], method = 'fdr_bh')[1]\n",
    "df2new_flt['BH_qval'] = multi.multipletests(df2new_flt['pval'], method = 'fdr_bh')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the intermediate tables with failed filters column but without removing anything\n",
    "with pd.ExcelWriter(fname, mode='a') as writer:  \n",
    "    df1new_flt.to_excel(writer, sheet_name=sh1+'_flt', na_rep = 'NA')\n",
    "    df2new_flt.to_excel(writer, sheet_name=sh2+'_flt', na_rep = 'NA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
